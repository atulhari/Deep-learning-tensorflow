{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91593564",
   "metadata": {},
   "source": [
    "## Part 2: Music generation with RNNs\n",
    "\n",
    "We will generate music using Reccurrent Neural Network (RNN). We will train a model to learn the patterns in the raw sheet music in ABC Notation and then use this model to generate new music."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82aa9e8",
   "metadata": {},
   "source": [
    "### 2.1 Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "687842b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 00:55:37.073070: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-04 00:55:37.129738: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-05-04 00:55:37.129760: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mitdeeplearning in /home/atul/.local/lib/python3.8/site-packages (0.3.0)\n",
      "Requirement already satisfied: numpy in /home/atul/.local/lib/python3.8/site-packages (from mitdeeplearning) (1.23.2)\n",
      "Requirement already satisfied: regex in /home/atul/.local/lib/python3.8/site-packages (from mitdeeplearning) (2023.5.4)\n",
      "Requirement already satisfied: tqdm in /home/atul/.local/lib/python3.8/site-packages (from mitdeeplearning) (4.64.1)\n",
      "Requirement already satisfied: gym in /home/atul/.local/lib/python3.8/site-packages (from mitdeeplearning) (0.26.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/atul/.local/lib/python3.8/site-packages (from gym->mitdeeplearning) (2.2.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /home/atul/.local/lib/python3.8/site-packages (from gym->mitdeeplearning) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in /home/atul/.local/lib/python3.8/site-packages (from gym->mitdeeplearning) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/atul/.local/lib/python3.8/site-packages (from importlib-metadata>=4.8.0->gym->mitdeeplearning) (3.7.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Import Tensorflow 2.0\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf \n",
    "\n",
    "# Download and import the MIT Introduction to Deep Learning package\n",
    "!pip install mitdeeplearning\n",
    "import mitdeeplearning as mdl\n",
    "\n",
    "# Import all remaining packages\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import functools\n",
    "from IPython import display as ipythondisplay\n",
    "from tqdm import tqdm\n",
    "!apt-get install abcmidi timidity > /dev/null 2>&1\n",
    "\n",
    "# Check that we are using a GPU, if not switch runtimes\n",
    "#   using Runtime > Change Runtime Type > GPU\n",
    "# assert len(tf.config.list_physical_devices('GPU')) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8fd7c2",
   "metadata": {},
   "source": [
    "### 2.2 Dataset\n",
    "We will use a dataset of thousand Irish folk songs collected by MIT, represented in the ABC notation.\n",
    "We will start by donwloading the dataset and inspecting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1939cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 817 songs in text\n",
      "\n",
      "Example song:\n",
      "X:2\n",
      "T:An Buachaill Dreoite\n",
      "Z: id:dc-hornpipe-2\n",
      "M:C|\n",
      "L:1/8\n",
      "K:G Major\n",
      "GF|DGGB d2GB|d2GF Gc (3AGF|DGGB d2GB|dBcA F2GF|!\n",
      "DGGB d2GF|DGGF G2Ge|fgaf gbag|fdcA G2:|!\n",
      "GA|B2BG c2cA|d2GF G2GA|B2BG c2cA|d2DE F2GA|!\n",
      "B2BG c2cA|d^cde f2 (3def|g2gf gbag|fdcA G2:|!\n"
     ]
    }
   ],
   "source": [
    "# Download the dataset\n",
    "songs = mdl.lab1.load_training_data()\n",
    "\n",
    "# Print one of the somgs to inspect it in great detail.\n",
    "example_song = songs[1]\n",
    "print(\"\\nExample song:\")\n",
    "print(example_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0157fba",
   "metadata": {},
   "source": [
    "We can convert the ABC notation to an audio file and then play it back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d0996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the ABC notation to audio file and listen to it.\n",
    "mdl.lab1.play_song(example_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ccea21",
   "metadata": {},
   "source": [
    "One important think about the notation of the music does not simply contain information on the notes being played, but additionally there is meta information such as the somg title, ker, and tempo. \n",
    "\n",
    "How does the number of different characters that are present in the text file impact the complexity of learning problem.\n",
    "\n",
    "This will become important soon, when we generate a numerical representation of the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e361c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 83 unique characters in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Lets join the list of songs into a single string containing all songs\n",
    "songs_joined = \"\\n\\n\".join(songs)\n",
    "\n",
    "# Find all unique characters in the joined string\n",
    "vocab = sorted(set(songs_joined))\n",
    "print(\"There are\", len(vocab), \"unique characters in the dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed2dfae",
   "metadata": {},
   "source": [
    "### 2.3 Process the dataset for the learning task\n",
    "We are training a RNN model to learn pattern in ABC music, and then use this model to generate (i.e, predict) a new piece of music based on this learned information. \n",
    "Basically what we are doing is given a set of characters, what is the most probable next character? We'll train the model to perform this task. \n",
    "To achieve this, we will input a sequence of characters to the model,and train the model to predict the output, that is the following characters at each time step.\n",
    "RNNs maintain an internal state that depends on previously seen elements and information about all characters seen up unitll a given moment will be taken into account in generating the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e6381",
   "metadata": {},
   "source": [
    "### Vectorize the text : Lookup table\n",
    "Before training our RNN model, we will need to create a numerial representation of our text-based dataset. To do this, we will generate two lookup tables.\n",
    "Lookup table1: Maps characters to numbers\n",
    "Lookup table2: Maps numbers to characters\n",
    "\n",
    "We can do this because all we care about is the unique characters present in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12541400",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the numerical representation of text ###\n",
    "\n",
    "# Create a mapping from characters to unique index.\n",
    "# For example, to get the index of the character \"d\", \n",
    "# We can evaluate `char2idx[\"d\"].\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "\n",
    "# Create a mapping from indices to characters. This is\n",
    "# the inverse from char2idx and allows us to convert back\n",
    "# from unique index to the char in our vocanbulary. \n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef13fc8",
   "metadata": {},
   "source": [
    "This gives us an integer representation for each character. Observe that the unique characters (i.e, our vocabulary) in the text are mapped as indices from 0 to `len(unique)`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6c43183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "'\\n': 0,\n",
      "' ': 1,\n",
      "'!': 2,\n",
      "'\"': 3,\n",
      "'#': 4,\n",
      "\"'\": 5,\n",
      "'(': 6,\n",
      "')': 7,\n",
      "',': 8,\n",
      "'-': 9,\n",
      "'.': 10,\n",
      "'/': 11,\n",
      "'0': 12,\n",
      "'1': 13,\n",
      "'2': 14,\n",
      "'3': 15,\n",
      "'4': 16,\n",
      "'5': 17,\n",
      "'6': 18,\n",
      "'7': 19,\n",
      " .. \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('{}: {},'.format(repr(char), char2idx[char]))\n",
    "print(' .. \\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8616d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'X:1\\nT:Alex' ---- characters mapped to int ----> [49 22 13  0 45 22 26 67 60 79]\n"
     ]
    }
   ],
   "source": [
    "### Vectorize the songs string ###\n",
    "def vectorize_string(string):\n",
    "    return np.array([char2idx[c] for c in string])\n",
    "\n",
    "vectorized_songs = vectorize_string(songs_joined)\n",
    "\n",
    "print ('{} ---- characters mapped to int ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))\n",
    "# check that vectorized_songs is a numpy array\n",
    "assert isinstance(vectorized_songs, np.ndarray), \"returned result should be a numpy array\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8acfea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
